#!/usr/bin/env python3
"""
Script to test any checkpoint on DAG examples.

This script:
1. Tries to load an existing checkpoint (or creates a mock one)
2. Tests the checkpoint on simple DAG examples like 1.0 + 1.0
3. Shows the model's predictions vs expected results
"""

import sys
from pathlib import Path

import torch
import torch.nn.functional as F

# Add the project root to the path
sys.path.append(str(Path(__file__).parent.parent))

import sympy

from checkpoint_manager import CheckpointManager
from data.dagset.streaming import expressions_to_tensors
from models.dag_model import GPT, GPTConfig
from models.predictor_only_model import PredictorOnlyConfig, PredictorOnlyModel


def create_mock_checkpoint():
    """Create a mock checkpoint for testing."""
    print("üîÑ Creating mock checkpoint for testing...")

    # Create a DAG predictor config matching train_predictor_config.py
    config = PredictorOnlyConfig(
        vocab_size=50257,
        block_size=32,
        n_layer=2,
        n_head=4,
        n_embd=256,  # n_head * 64 = 4 * 64 = 256
        dropout=0.1,
        bias=True,
        dag_depth=4,
        max_digits=4,
        max_decimal_places=4,
    )

    # Create model
    model = PredictorOnlyModel(config)

    # Create mock checkpoint data
    checkpoint = {
        "model": model.state_dict(),
        "model_args": config,
        "iter_num": 1000,
        "best_val_loss": 0.1,
    }

    print(
        f"‚úÖ Mock checkpoint created with {sum(p.numel() for p in model.parameters()):,} parameters"
    )
    return model, config, checkpoint


def load_existing_checkpoint(checkpoint_path: Path = None):
    """Load an existing checkpoint or try to download from RunPod."""
    checkpoint_manager = CheckpointManager()

    # If no checkpoint path provided, try to download from RunPod
    if checkpoint_path is None:
        print(f"üîÑ No checkpoint provided, attempting to download from RunPod...")
        runpod_path = "/runpod-volume/checkpoints/rhfuok9btu6t8m-pretrained_sharp/ckpt_predictor_pretrain_8600_99.98acc.pt"
        local_dir = Path("runpod_checkpoints")

        downloaded_path = checkpoint_manager.download_checkpoint_from_runpod(
            runpod_path, local_dir
        )
        if downloaded_path and downloaded_path.exists():
            print(f"‚úÖ Successfully downloaded checkpoint to: {downloaded_path}")
            checkpoint_path = downloaded_path
        else:
            print(f"‚ùå Failed to download from RunPod")
            raise FileNotFoundError("Failed to download checkpoint from RunPod")

    # Load the checkpoint
    if checkpoint_path and checkpoint_path.exists():
        print(f"üîÑ Loading checkpoint from {checkpoint_path}...")
        try:
            checkpoint = checkpoint_manager.load_checkpoint_from_path(checkpoint_path)

            # Handle different checkpoint formats
            if "model_args" in checkpoint:
                model_args = checkpoint["model_args"]
            elif "model_config" in checkpoint:
                # Convert dictionary to config object
                config_dict = checkpoint["model_config"]
                if "dag_depth" in config_dict and config_dict["dag_depth"] > 0:
                    # Filter out extra fields for PredictorOnlyConfig
                    valid_fields = [
                        "vocab_size",
                        "n_layer",
                        "n_embd",
                        "n_head",
                        "dropout",
                        "bias",
                        "dag_depth",
                        "block_size",
                        "max_digits",
                        "max_decimal_places",
                    ]
                    filtered_config = {
                        k: v for k, v in config_dict.items() if k in valid_fields
                    }
                    model_args = PredictorOnlyConfig(**filtered_config)
                else:
                    model_args = GPTConfig(**config_dict)
            else:
                raise KeyError(
                    "Neither 'model_args' nor 'model_config' found in checkpoint"
                )

            # Create model
            if isinstance(model_args, PredictorOnlyConfig):
                model = PredictorOnlyModel(model_args)
                model_type = "DAG Predictor"
            else:
                model = GPT(model_args)
                model_type = "DAG-GPT"

            # Load state dict
            model.load_state_dict(checkpoint["model"])
            print(f"‚úÖ {model_type} model loaded successfully")
            print(
                f"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}"
            )

            return model, model_args, checkpoint

        except Exception as e:
            print(f"‚ùå Error loading checkpoint: {e}")
            raise e

    # If we get here, no checkpoint was provided and download failed
    raise FileNotFoundError("No checkpoint provided and download from RunPod failed")


def test_dag_examples(model, config):
    """Test the model on various DAG examples."""
    print(f"\nüß™ Testing DAG examples...")

    model.eval()

    # Test examples
    test_expressions = [
        "1.0 + 1.0",
        "2.0 * 3.0",
        "10.0 - 5.0",
        "15.0 / 3.0",
        "1.5 + 2.5",
        "3.0 * 4.0",
        "8.0 - 2.0",
        "12.0 / 4.0",
    ]

    print(f"üìù Testing {len(test_expressions)} expressions:")

    for i, expr_str in enumerate(test_expressions):
        print(f"\n   Example {i+1}: {expr_str}")

        try:
            # Parse expression
            expr = sympy.parse_expr(expr_str)
            expected_result = float(expr.evalf())

            # Convert to tensors
            target_tensors, valid_mask = expressions_to_tensors(
                [expr],
                depth=config.dag_depth,
                max_digits=config.max_digits,
                max_decimal_places=config.max_decimal_places,
            )

            if not valid_mask[0]:
                print(f"     ‚ùå Expression not valid for DAG depth {config.dag_depth}")
                continue

            target = target_tensors[0]

            # For testing, we'll create a simple input that the model can process
            # The model expects token IDs, not the DAG tensors directly
            # Let's create a simple test input and just show the model outputs

            # Create a simple token sequence input
            test_input = torch.randint(
                0, 1000, (1, 10)
            )  # batch_size=1, sequence_length=10

            with torch.no_grad():
                if isinstance(model, PredictorOnlyModel):
                    # DAG Predictor - get predictions
                    pred_digit_logits, pred_V_sign, pred_O, pred_G = model(test_input)

                    # Show model outputs
                    print(f"     - Model produced predictions:")
                    print(f"       * Digit logits shape: {pred_digit_logits.shape}")
                    print(f"       * V_sign shape: {pred_V_sign.shape}")
                    print(f"       * O shape: {pred_O.shape}")
                    print(f"       * G shape: {pred_G.shape}")

                    # Show some sample values
                    print(f"       * Sample V_sign: {pred_V_sign[0, 0, :3].tolist()}")
                    print(f"       * Sample G: {pred_G[0, 0, :3].tolist()}")

                    # Try to execute the predicted DAG
                    try:
                        from models.dag_model import DAGExecutor

                        executor = DAGExecutor(
                            dag_depth=config.dag_depth,
                            max_digits=config.max_digits,
                            max_decimal_places=config.max_decimal_places,
                        )

                        # Execute the predicted DAG
                        dag_result = executor.forward(
                            pred_digit_logits, pred_V_sign, pred_O, pred_G
                        )
                        predicted_result = dag_result[0, 0].item()

                        print(f"     - DAG execution successful!")
                        print(f"     - Predicted result: {predicted_result:.6f}")

                    except Exception as e:
                        print(f"     - DAG execution failed: {e}")
                        predicted_result = 0.0  # Fallback

                else:
                    # DAG-GPT model
                    dag_result = model(test_input)
                    predicted_result = dag_result[0, 0].item()

            # Show results
            print(f"     - Expected: {expected_result:.6f}")

            # Calculate error if we have a prediction
            if predicted_result != 0.0:  # Not the fallback value
                error = abs(predicted_result - expected_result)
                error_percent = (
                    (error / abs(expected_result)) * 100
                    if expected_result != 0
                    else float("inf")
                )

                print(f"     - Error: {error:.6f} ({error_percent:.2f}%)")

                if error < 0.1:
                    print(f"     ‚úÖ Good prediction!")
                elif error < 1.0:
                    print(f"     ‚ö†Ô∏è  Moderate error")
                else:
                    print(f"     ‚ùå Large error")
            else:
                print(f"     - Note: DAG execution failed, showing model outputs only")

        except Exception as e:
            print(f"     ‚ùå Error processing expression: {e}")


def test_model_behavior(model, config):
    """Test basic model behavior and outputs."""
    print(f"\nüß™ Testing model behavior...")

    model.eval()

    # Create a simple test input - use token IDs format
    test_input = torch.randint(0, 1000, (1, 10))  # batch_size=1, sequence_length=10

    with torch.no_grad():
        if isinstance(model, PredictorOnlyModel):
            outputs = model(test_input)
            digit_logits, V_sign, O, G = outputs

            print(f"üìä DAG Predictor outputs:")
            print(f"   - Digit logits: {digit_logits.shape}")
            print(f"   - V_sign: {V_sign.shape}")
            print(f"   - O: {O.shape}")
            print(f"   - G: {G.shape}")

            # Show some sample values
            print(f"   - Sample V_sign values: {V_sign[0, 0, :3].tolist()}")
            print(f"   - Sample G values: {G[0, 0, :3].tolist()}")

        else:
            dag_results = model(test_input)
            print(f"üìä DAG-GPT outputs:")
            print(f"   - Output shape: {dag_results.shape}")
            print(f"   - Sample values: {dag_results[0, :3].tolist()}")

    print(f"‚úÖ Model behavior test successful")


def main():
    """Main function to test checkpoint on examples."""
    print("üöÄ Checkpoint Examples Testing Script")
    print("=" * 50)

    # Check if checkpoint path provided
    checkpoint_path = None
    if len(sys.argv) > 1:
        checkpoint_path = Path(sys.argv[1])
        print(f"üìÅ Using checkpoint: {checkpoint_path}")

    # Load checkpoint (or create mock)
    model, config, checkpoint = load_existing_checkpoint(checkpoint_path)

    # Test DAG examples
    test_dag_examples(model, config)

    # Test model behavior
    test_model_behavior(model, config)

    print(f"\n‚úÖ All tests completed successfully!")

    if checkpoint_path is None:
        print(f"üí° To test a real checkpoint, run:")
        print(f"   python scripts/test_checkpoint_examples.py <checkpoint_path>")


if __name__ == "__main__":
    main()
